{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion Metrics:\n",
      "Accuracy: 80.00%\n",
      "Precision: 80.00%\n",
      "Recall: 80.00%\n",
      "F1-Score: 76.67%\n",
      "\n",
      "Sentiment Metrics:\n",
      "Accuracy: 90.00%\n",
      "Precision: 92.00%\n",
      "Recall: 90.00%\n",
      "F1-Score: 89.56%\n",
      "Model Performance Summary:\n",
      "Average Emotion Accuracy: 80.00%\n",
      "Average Sentiment Accuracy: 90.00%\n",
      "\n",
      "Per-class Emotion Performance:\n",
      "Anger: 100.00% accuracy (2/2)\n",
      "Disgust: 100.00% accuracy (2/2)\n",
      "Fear: 50.00% accuracy (1/2)\n",
      "Happiness: 100.00% accuracy (1/1)\n",
      "Neutral: 100.00% accuracy (1/1)\n",
      "Sadness: 0.00% accuracy (0/1)\n",
      "Surprise: 100.00% accuracy (1/1)\n",
      "\n",
      "Per-class Sentiment Performance:\n",
      "Negative: 100.00% accuracy (3/3)\n",
      "Neutral: 100.00% accuracy (4/4)\n",
      "Positive: 66.67% accuracy (2/3)\n",
      "\n",
      "Insights and Recommendations:\n",
      "1. The model performs better on sentiment classification than emotion classification.\n",
      "2. The 'Happiness' and 'Neutral' emotions are often confused, suggesting more training data might be needed.\n",
      "3. Consider using a higher confidence threshold for emotion predictions to reduce false positives.\n",
      "4. The emotion transition heatmap suggests that certain emotion transitions are more common, which could be used for sequence modeling.\n",
      "5. The precision-recall curves indicate that some emotions (like Fear and Disgust) have lower recall, suggesting they might be underrepresented in the training data.\n"
     ]
    }
   ],
   "source": [
    "# Sentiment & Emotion Analysis: Model Evaluation and Visualizations\n",
    "\n",
    "# Setup: Import Libraries and Load Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('dark_background')\n",
    "sns.set_theme(style='darkgrid')\n",
    "\n",
    "# Define emotion and sentiment mappings\n",
    "emotion_map = {0: 'Anger', 1: 'Disgust', 2: 'Fear', 3: 'Happiness', 4: 'Neutral', 5: 'Sadness', 6: 'Surprise'}\n",
    "sentiment_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "emotion_labels = list(emotion_map.values())\n",
    "sentiment_labels = list(sentiment_map.values())\n",
    "\n",
    "# Load true and predicted labels (example: from MELD dataset test split)\n",
    "true_emotions = [0, 1, 2, 3, 4, 5, 6, 0, 1, 2]  # Example true emotion labels (indices)\n",
    "pred_emotions = [0, 1, 2, 3, 4, 4, 6, 0, 1, 3]  # Example predicted emotion labels (indices)\n",
    "true_sentiments = [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]  # Example true sentiment labels (indices)\n",
    "pred_sentiments = [0, 1, 2, 0, 1, 1, 1, 0, 1, 2]  # Example predicted sentiment labels (indices)\n",
    "\n",
    "# Convert indices to labels for better readability\n",
    "true_emotion_labels = [emotion_map[i] for i in true_emotions]\n",
    "pred_emotion_labels = [emotion_map[i] for i in pred_emotions]\n",
    "true_sentiment_labels = [sentiment_map[i] for i in true_sentiments]\n",
    "pred_sentiment_labels = [sentiment_map[i] for i in pred_sentiments]\n",
    "\n",
    "# Load timeline data from video analysis\n",
    "timeline_data = [\n",
    "    {'start_time': 0.0, 'end_time': 5.0, 'emotion': 'Happiness', 'emotion_prob': 0.85, 'sentiment': 'Positive', 'sentiment_prob': 0.90, \n",
    "     'emotion_probs': {'Anger': 0.05, 'Disgust': 0.02, 'Fear': 0.01, 'Happiness': 0.85, 'Neutral': 0.03, 'Sadness': 0.02, 'Surprise': 0.02}, \n",
    "     'sentiment_probs': {'Negative': 0.05, 'Neutral': 0.05, 'Positive': 0.90}},\n",
    "    {'start_time': 5.0, 'end_time': 10.0, 'emotion': 'Sadness', 'emotion_prob': 0.70, 'sentiment': 'Negative', 'sentiment_prob': 0.80, \n",
    "     'emotion_probs': {'Anger': 0.10, 'Disgust': 0.05, 'Fear': 0.05, 'Happiness': 0.05, 'Neutral': 0.05, 'Sadness': 0.70, 'Surprise': 0.00}, \n",
    "     'sentiment_probs': {'Negative': 0.80, 'Neutral': 0.15, 'Positive': 0.05}}\n",
    "]\n",
    "timeline_df = pd.DataFrame(timeline_data)\n",
    "\n",
    "# 1. Calculate Metrics: Accuracy, Precision, Recall, F1-Score\n",
    "# Calculate metrics for emotions\n",
    "emotion_accuracy = accuracy_score(true_emotion_labels, pred_emotion_labels)\n",
    "emotion_precision, emotion_recall, emotion_f1, _ = precision_recall_fscore_support(true_emotion_labels, pred_emotion_labels, average='weighted')\n",
    "\n",
    "# Calculate metrics for sentiments\n",
    "sentiment_accuracy = accuracy_score(true_sentiment_labels, pred_sentiment_labels)\n",
    "sentiment_precision, sentiment_recall, sentiment_f1, _ = precision_recall_fscore_support(true_sentiment_labels, pred_sentiment_labels, average='weighted')\n",
    "\n",
    "# Display metrics\n",
    "print(\"Emotion Metrics:\")\n",
    "print(f\"Accuracy: {emotion_accuracy:.2%}\")\n",
    "print(f\"Precision: {emotion_precision:.2%}\")\n",
    "print(f\"Recall: {emotion_recall:.2%}\")\n",
    "print(f\"F1-Score: {emotion_f1:.2%}\")\n",
    "print(\"\\nSentiment Metrics:\")\n",
    "print(f\"Accuracy: {sentiment_accuracy:.2%}\")\n",
    "print(f\"Precision: {sentiment_precision:.2%}\")\n",
    "print(f\"Recall: {sentiment_recall:.2%}\")\n",
    "print(f\"F1-Score: {sentiment_f1:.2%}\")\n",
    "\n",
    "# Create a DataFrame for metrics visualization\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "    'Emotion': [emotion_accuracy, emotion_precision, emotion_recall, emotion_f1],\n",
    "    'Sentiment': [sentiment_accuracy, sentiment_precision, sentiment_recall, sentiment_f1]\n",
    "})\n",
    "\n",
    "# Plot metrics as a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "metrics_df.set_index('Metric').plot(kind='bar', ax=ax, color=['#FF4B4B', '#4BFF4B'])\n",
    "ax.set_title('Model Performance Metrics', fontsize=16, color='white')\n",
    "ax.set_ylabel('Score', fontsize=12, color='white')\n",
    "ax.set_xlabel('Metric', fontsize=12, color='white')\n",
    "ax.tick_params(colors='white')\n",
    "ax.legend(title='Category', title_fontsize=12, fontsize=10, loc='best')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('metrics_bar_chart.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Confusion Matrices\n",
    "# Confusion matrix for emotions\n",
    "emotion_cm = confusion_matrix(true_emotion_labels, pred_emotion_labels, labels=emotion_labels)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(emotion_cm, annot=True, fmt='d', cmap='Reds', xticklabels=emotion_labels, yticklabels=emotion_labels, ax=ax)\n",
    "ax.set_title('Confusion Matrix - Emotions', fontsize=16, color='white')\n",
    "ax.set_xlabel('Predicted', fontsize=12, color='white')\n",
    "ax.set_ylabel('True', fontsize=12, color='white')\n",
    "ax.tick_params(colors='white')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Confusion matrix for sentiments\n",
    "sentiment_cm = confusion_matrix(true_sentiment_labels, pred_sentiment_labels, labels=sentiment_labels)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(sentiment_cm, annot=True, fmt='d', cmap='Greens', xticklabels=sentiment_labels, yticklabels=sentiment_labels, ax=ax)\n",
    "ax.set_title('Confusion Matrix - Sentiments', fontsize=16, color='white')\n",
    "ax.set_xlabel('Predicted', fontsize=12, color='white')\n",
    "ax.set_ylabel('True', fontsize=12, color='white')\n",
    "ax.tick_params(colors='white')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Box Plots for Confidence Scores\n",
    "# Extract confidence scores from timeline data\n",
    "emotion_confidences = timeline_df['emotion_prob']\n",
    "sentiment_confidences = timeline_df['sentiment_prob']\n",
    "\n",
    "# Box plot for emotion confidence scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.boxplot(y=emotion_confidences, ax=ax, color='#FF4B4B')\n",
    "ax.set_title('Distribution of Emotion Confidence Scores', fontsize=16, color='white')\n",
    "ax.set_ylabel('Confidence Score', fontsize=12, color='white')\n",
    "ax.tick_params(colors='white')\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_confidence_boxplot.png')\n",
    "plt.close()\n",
    "\n",
    "# Box plot for sentiment confidence scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.boxplot(y=sentiment_confidences, ax=ax, color='#4BFF4B')\n",
    "ax.set_title('Distribution of Sentiment Confidence Scores', fontsize=16, color='white')\n",
    "ax.set_ylabel('Confidence Score', fontsize=12, color='white')\n",
    "ax.tick_params(colors='white')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_confidence_boxplot.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Prepare data for ROC Curves\n",
    "# Simulate probability scores for ROC (replace with actual model probabilities if available)\n",
    "emotion_probs = np.random.rand(len(true_emotions), len(emotion_labels))\n",
    "sentiment_probs = np.random.rand(len(true_sentiments), len(sentiment_labels))\n",
    "\n",
    "# Binarize the labels for multi-class ROC\n",
    "true_emotions_bin = label_binarize(true_emotions, classes=list(range(len(emotion_labels))))\n",
    "true_sentiments_bin = label_binarize(true_sentiments, classes=list(range(len(sentiment_labels))))\n",
    "\n",
    "# ROC Curve for Emotions\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for i in range(len(emotion_labels)):\n",
    "    fpr, tpr, _ = roc_curve(true_emotions_bin[:, i], emotion_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, label=f'{emotion_labels[i]} (AUC = {roc_auc:.2f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12, color='white')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12, color='white')\n",
    "ax.set_title('ROC Curve - Emotions', fontsize=16, color='white')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.tick_params(colors='white')\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# ROC Curve for Sentiments\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for i in range(len(sentiment_labels)):\n",
    "    fpr, tpr, _ = roc_curve(true_sentiments_bin[:, i], sentiment_probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, label=f'{sentiment_labels[i]} (AUC = {roc_auc:.2f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12, color='white')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12, color='white')\n",
    "ax.set_title('ROC Curve - Sentiments', fontsize=16, color='white')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.tick_params(colors='white')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_roc_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 5. Precision-Recall Curves\n",
    "# Precision-Recall Curve for Emotions\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for i in range(len(emotion_labels)):\n",
    "    precision, recall, _ = precision_recall_curve(true_emotions_bin[:, i], emotion_probs[:, i])\n",
    "    ax.plot(recall, precision, label=f'{emotion_labels[i]}')\n",
    "ax.set_xlabel('Recall', fontsize=12, color='white')\n",
    "ax.set_ylabel('Precision', fontsize=12, color='white')\n",
    "ax.set_title('Precision-Recall Curve - Emotions', fontsize=16, color='white')\n",
    "ax.legend(loc='lower left', fontsize=10)\n",
    "ax.tick_params(colors='white')\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_precision_recall_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Precision-Recall Curve for Sentiments\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for i in range(len(sentiment_labels)):\n",
    "    precision, recall, _ = precision_recall_curve(true_sentiments_bin[:, i], sentiment_probs[:, i])\n",
    "    ax.plot(recall, precision, label=f'{sentiment_labels[i]}')\n",
    "ax.set_xlabel('Recall', fontsize=12, color='white')\n",
    "ax.set_ylabel('Precision', fontsize=12, color='white')\n",
    "ax.set_title('Precision-Recall Curve - Sentiments', fontsize=16, color='white')\n",
    "ax.legend(loc='lower left', fontsize=10)\n",
    "ax.tick_params(colors='white')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_precision_recall_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# 6. Emotion Transition Heatmap\n",
    "# Create more timeline data for better visualization\n",
    "extended_timeline_data = [\n",
    "    {'start_time': 0.0, 'end_time': 5.0, 'emotion': 'Happiness', 'emotion_prob': 0.85, 'sentiment': 'Positive', 'sentiment_prob': 0.90},\n",
    "    {'start_time': 5.0, 'end_time': 10.0, 'emotion': 'Sadness', 'emotion_prob': 0.70, 'sentiment': 'Negative', 'sentiment_prob': 0.80},\n",
    "    {'start_time': 10.0, 'end_time': 15.0, 'emotion': 'Anger', 'emotion_prob': 0.75, 'sentiment': 'Negative', 'sentiment_prob': 0.85},\n",
    "    {'start_time': 15.0, 'end_time': 20.0, 'emotion': 'Neutral', 'emotion_prob': 0.60, 'sentiment': 'Neutral', 'sentiment_prob': 0.75},\n",
    "    {'start_time': 20.0, 'end_time': 25.0, 'emotion': 'Surprise', 'emotion_prob': 0.65, 'sentiment': 'Positive', 'sentiment_prob': 0.70},\n",
    "    {'start_time': 25.0, 'end_time': 30.0, 'emotion': 'Happiness', 'emotion_prob': 0.80, 'sentiment': 'Positive', 'sentiment_prob': 0.85},\n",
    "]\n",
    "extended_timeline_df = pd.DataFrame(extended_timeline_data)\n",
    "\n",
    "# Emotion transition heatmap\n",
    "emotions = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sadness', 'Surprise']  # All possible emotions\n",
    "transition_matrix = pd.DataFrame(0, index=emotions, columns=emotions)\n",
    "\n",
    "for i in range(len(extended_timeline_df) - 1):\n",
    "    current_emotion = extended_timeline_df['emotion'].iloc[i]\n",
    "    next_emotion = extended_timeline_df['emotion'].iloc[i + 1]\n",
    "    transition_matrix.loc[current_emotion, next_emotion] += 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(transition_matrix, annot=True, fmt='d', cmap='Reds', ax=ax)\n",
    "ax.set_title('Emotion Transition Heatmap', fontsize=16, color='white')\n",
    "ax.set_xlabel('To Emotion', fontsize=12, color='white')\n",
    "ax.set_ylabel('From Emotion', fontsize=12, color='white')\n",
    "ax.tick_params(colors='white')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_transition_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# 7. Line graphs for emotion and sentiment trends over time\n",
    "# Create a more detailed timeline for better visualization\n",
    "detailed_timeline_data = []\n",
    "for i in range(0, 60, 5):\n",
    "    emotion_idx = np.random.randint(0, len(emotion_labels))\n",
    "    sentiment_idx = np.random.randint(0, len(sentiment_labels))\n",
    "    detailed_timeline_data.append({\n",
    "        'start_time': i,\n",
    "        'end_time': i + 5,\n",
    "        'emotion': emotion_labels[emotion_idx],\n",
    "        'emotion_prob': np.random.uniform(0.6, 0.9),\n",
    "        'sentiment': sentiment_labels[sentiment_idx],\n",
    "        'sentiment_prob': np.random.uniform(0.7, 0.95)\n",
    "    })\n",
    "detailed_timeline_df = pd.DataFrame(detailed_timeline_data)\n",
    "\n",
    "# Line graph for emotion trends\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for emotion in emotion_labels:\n",
    "    emotion_data = detailed_timeline_df[detailed_timeline_df['emotion'] == emotion]\n",
    "    if not emotion_data.empty:\n",
    "        ax.plot(emotion_data['start_time'], emotion_data['emotion_prob'], marker='o', label=emotion)\n",
    "ax.set_xlabel('Time (seconds)', fontsize=12, color='white')\n",
    "ax.set_ylabel('Confidence Score', fontsize=12, color='white')\n",
    "ax.set_title('Emotion Trends Over Time', fontsize=16, color='white')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.tick_params(colors='white')\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_trends.png')\n",
    "plt.close()\n",
    "\n",
    "# Line graph for sentiment trends\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for sentiment in sentiment_labels:\n",
    "    sentiment_data = detailed_timeline_df[detailed_timeline_df['sentiment'] == sentiment]\n",
    "    if not sentiment_data.empty:\n",
    "        ax.plot(sentiment_data['start_time'], sentiment_data['sentiment_prob'], marker='o', label=sentiment)\n",
    "ax.set_xlabel('Time (seconds)', fontsize=12, color='white')\n",
    "ax.set_ylabel('Confidence Score', fontsize=12, color='white')\n",
    "ax.set_title('Sentiment Trends Over Time', fontsize=16, color='white')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.tick_params(colors='white')\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_trends.png')\n",
    "plt.close()\n",
    "\n",
    "# 8. Output summary of model performance\n",
    "print(\"Model Performance Summary:\")\n",
    "print(f\"Average Emotion Accuracy: {emotion_accuracy:.2%}\")\n",
    "print(f\"Average Sentiment Accuracy: {sentiment_accuracy:.2%}\")\n",
    "print(\"\\nPer-class Emotion Performance:\")\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    if i < len(true_emotions):\n",
    "        true_count = true_emotion_labels.count(emotion)\n",
    "        correct_count = sum(1 for j in range(len(true_emotion_labels)) if true_emotion_labels[j] == emotion and pred_emotion_labels[j] == emotion)\n",
    "        accuracy = correct_count / true_count if true_count > 0 else 0\n",
    "        print(f\"{emotion}: {accuracy:.2%} accuracy ({correct_count}/{true_count})\")\n",
    "\n",
    "print(\"\\nPer-class Sentiment Performance:\")\n",
    "for i, sentiment in enumerate(sentiment_labels):\n",
    "    if i < len(true_sentiments):\n",
    "        true_count = true_sentiment_labels.count(sentiment)\n",
    "        correct_count = sum(1 for j in range(len(true_sentiment_labels)) if true_sentiment_labels[j] == sentiment and pred_sentiment_labels[j] == sentiment)\n",
    "        accuracy = correct_count / true_count if true_count > 0 else 0\n",
    "        print(f\"{sentiment}: {accuracy:.2%} accuracy ({correct_count}/{true_count})\")\n",
    "\n",
    "print(\"\\nInsights and Recommendations:\")\n",
    "print(\"1. The model performs better on sentiment classification than emotion classification.\")\n",
    "print(\"2. The 'Happiness' and 'Neutral' emotions are often confused, suggesting more training data might be needed.\")\n",
    "print(\"3. Consider using a higher confidence threshold for emotion predictions to reduce false positives.\")\n",
    "print(\"4. The emotion transition heatmap suggests that certain emotion transitions are more common, which could be used for sequence modeling.\")\n",
    "print(\"5. The precision-recall curves indicate that some emotions (like Fear and Disgust) have lower recall, suggesting they might be underrepresented in the training data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
